\section{\SYSTEM{} Implementation} \label{sec:implementation}

Our implementation of \SYSTEM{} is comprised of 5000 lines of C code. Libraries
used by \SYSTEM{} include OpenSSL version 1.0.2 and LibSodium version 1.0.12 for
its ChaCha20, Argon2, Blake2, and AES-XTS implementations, likewise implemented
in C. The SHA-256 Merkle Tree implementation is borrowed from the Secure Block
Device library~\cite{SBD}. The implementation is available at
https://github.com/ananonrepo2/StrongBox.

To reduce the complexity of the experimental setup and allow \SYSTEM{}
to run in user space, we provide a virtual device interface through
the BUSE~\cite{BUSE} virtual block device layer, itself based on the
Network Block Device (NBD).

\subsection{Deriving Subkeys}
To function, the cryptographic driver must be made aware of a shared
master secret. The method of derivation of this master secret is
implementation specific and has no impact on performance as it is
completed during \SYSTEM{}'s initialization. Our implementation of
\SYSTEM{} utilizes the Argon2 KDF to derive a master secret from a
given password with an acceptable time-memory trade-off.

% Describe deriving the nugget keys from the master secret
To assign each nugget its own unique keystream, that nugget requires a
unique key and associated nonce. Our implementation of \SYSTEM{}
derives these nugget subkeys from the master secret during \SYSTEM{}'s
initialization. To guarantee the backing store's integrity, each flake
is tagged with a MAC. Our implementation of \SYSTEM{} uses Poly1305,
accepting a 32-byte one-time key and a plaintext of arbitrary length
to generate tags. These one-time flake subkeys are derived from their
respective nugget subkeys.

\subsection{A Secure, Persistent Counter} 

Our target platform uses an embedded Multi-Media Card (eMMC) as a backing store. In
addition to boot and user data partitions, the eMMC standard includes a secure storage
partition called a Replay Protected Memory Block (RPMB)~\cite{eMMC-standard}. The RPMB
partition's size is fixed at manufacturing time, and all read and write commands issued
to it must be authenticated by a key that is fixed when the device is first set up.

To implement rollback protection on top of the RPMB, the key for authenticating RPMB
commands could be sealed in TEE sealed storage so that it would only be accessible to a
specific enclave running in a TEE. This enclave would be responsible for reading and
writing the \SYSTEM{} global version counter to the RPMB, and enforcing that invariant
that it only increase monotonically. Our design is not dependent on the eMMC standard,
however. Other trusted hardware mechanisms, including TPMs, support secure, persistent
storage or monotonic counters that could be adapted for use with \SYSTEM{}.

There are two practical concerns we must address for implementing the
secure counter: wear and performance overhead.  Wear is a concern because the
counter is implemented in non-volatile storage.  The RPMB implements
all the same wear protection mechanisms that are used to store
user-data~\cite{eMMC-standard}.  In addition, \SYSTEM{} writes to the
global version counter once per write to user-data.  Given that the
eMMC implements the same wear protection for the RPMB and user data,
and that the ratio of writes to these areas is 1:1, we expect
\SYSTEM{} places no additional wear burden on the hardware.  In terms
of performance overhead, updating the global version counter requires
making one 64-bit authenticated write per user-data write.  As
user-data writes will almost always be substantially larger, we
anticipate no significant overhead from the using the RPMB to store
the secure counter.

\subsection{LFS Garbage Collection}

% What is this? Why is this necessary?
An LFS attempts to write to a disk sequentially and in an append-only fashion,
as if it were writing to a log. This requires large amounts of contiguous space
on disk, called \emph{segments}. Since any backing store is necessarily finite
in capacity, an LFS can only append so much data before it runs out of free
space. When this occurs, the LFS triggers a \emph{segment cleaning algorithm} to
erase any outdated data and compress the remainder of the log down into as few
segments as possible~\cite{LFS,F2FS}. This segment cleaning procedure is known
more broadly as \emph{garbage collection}~\cite{F2FS}.

In the context of \SYSTEM{}, garbage collection could potentially
incur high overhead. The procedure itself would, with its every write,
require a rekeying of any affected nuggets. Worse, every proceeding
write would appear to \SYSTEM{} as if it were an overwrite, since
there is no way for \SYSTEM{} to know that the LFS triggered garbage
collection internally.

In practice, modern production LFSes are optimized to perform garbage collection
as few times as possible~\cite{F2FS}. Further, they often perform garbage
collection in a background thread that triggers when the filesystem is idle and
only perform expensive on-demand garbage collection when the backing store is
nearing capacity~\cite{F2FS, NILFS}. We leave garbage collection turned on for
all of our tests and see no substantial performance degradation from this
process because it is scheduled not to interfere with user I/O.
